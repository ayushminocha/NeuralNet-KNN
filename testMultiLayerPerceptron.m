function Output = testMultiLayerPerceptron(input, target, Model)
% testMultiLayerPerceptron(input, target, Model)
% input: Test data points 
% target: Target classes corresponding to the input data points
% Model: Model returned by the trainMultiLayerPerceptron function
%
% Outputs
% Output: Contains the outputs generated by the MLP

if nargin < 3
    help('testMultiLayerPerceptron')
    return;
end

Activations = cell(1,Model.numHiddenLayers);

%%Add bias input
input(:,size(input,2)+1) = -1;

Output = [];

for inp = 1:size(input,1)
    %%Find Activations
    Activations{1} = input(inp,:); %%First layer activations are the inputs
    
    for levels = 2:Model.numHiddenLayers
        h = Activations{levels-1}*Model.Weights{levels-1};
        Activations{levels} = activationFunction(Model.activationF,h,Model);
        Activations{levels} = [Activations{levels} -1];  %%Adding the values for the Bias
        if Activations{levels} == inf
            ME = MException('trainSingleLayerPerceptron:noSuchActivationFunction','Activation function %s not found',options.activationF);
            throw(ME);
        end
    end
    
    Output = [Output;Activations{Model.numHiddenLayers}(1:end-1)];
end

end